{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 13, 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "from elasticsearch import Elasticsearch\n",
    "import elasticsearch\n",
    "from elasticsearch.helpers import bulk\n",
    "\n",
    "print(elasticsearch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!! CUSTOMIZE THIS SECTION WITH YOUR CREDENTIALS !!!\n",
    "\n",
    "USER = 'elastic'\n",
    "PWD = 'YOUR_PWD_HERE'\n",
    "index_name = 'books'\n",
    "ES_ENDPOINT = 'https://localhost:9200'\n",
    "\n",
    "path_to_ca_certificates = '/PATH/TO/elasticsearch-8.5.3/config/certs/http_ca.crt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_name</th>\n",
       "      <th>title</th>\n",
       "      <th>country</th>\n",
       "      <th>language</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14602826</th>\n",
       "      <td>Yearsley, Ann</td>\n",
       "      <td>Poems on several occasions</td>\n",
       "      <td>England</td>\n",
       "      <td>English</td>\n",
       "      <td>1786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14602830</th>\n",
       "      <td>A, T.</td>\n",
       "      <td>A Satyr against Vertue. (A poem: supposed to b...</td>\n",
       "      <td>England</td>\n",
       "      <td>English</td>\n",
       "      <td>1679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14602831</th>\n",
       "      <td>A, T.</td>\n",
       "      <td>The Aeronaut, a poem; founded almost entirely,...</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>English</td>\n",
       "      <td>1816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14602832</th>\n",
       "      <td>Albert, Prince Consort, consort of Victoria, Q...</td>\n",
       "      <td>The Prince Albert, a poem</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>English</td>\n",
       "      <td>1868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14602833</th>\n",
       "      <td>Anslow, Robert</td>\n",
       "      <td>The Defeat of the Spanish Armada, A.D. 1588. A...</td>\n",
       "      <td>England</td>\n",
       "      <td>English</td>\n",
       "      <td>1888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                author_name  \\\n",
       "id                                                            \n",
       "14602826                                      Yearsley, Ann   \n",
       "14602830                                              A, T.   \n",
       "14602831                                              A, T.   \n",
       "14602832  Albert, Prince Consort, consort of Victoria, Q...   \n",
       "14602833                                     Anslow, Robert   \n",
       "\n",
       "                                                      title  country language  \\\n",
       "id                                                                              \n",
       "14602826                         Poems on several occasions  England  English   \n",
       "14602830  A Satyr against Vertue. (A poem: supposed to b...  England  English   \n",
       "14602831  The Aeronaut, a poem; founded almost entirely,...  Ireland  English   \n",
       "14602832                          The Prince Albert, a poem  Ireland  English   \n",
       "14602833  The Defeat of the Spanish Armada, A.D. 1588. A...  England  English   \n",
       "\n",
       "          year  \n",
       "id              \n",
       "14602826  1786  \n",
       "14602830  1679  \n",
       "14602831  1816  \n",
       "14602832  1868  \n",
       "14602833  1888  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('books.csv')\n",
    "df = df.set_index('id')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14602826\n",
      "{'author_name': 'Yearsley, Ann', 'title': 'Poems on several occasions', 'country': 'England', 'language': 'English', 'year': 1786}\n"
     ]
    }
   ],
   "source": [
    "#transform dataframe into json format\n",
    "docs = df.to_dict(orient='records')\n",
    "doc_ids = df.index\n",
    "print(doc_ids[0])\n",
    "print(docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Elasticsearch Python wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index(es, index_name, settings=None):\n",
    "    \"\"\"\n",
    "    Create an Elasticsearch index\n",
    "    @param es: an Elasticsearch object\n",
    "    @param index_name: the name of the new index to be created\n",
    "    @param settings: the index settings\n",
    "    @return whether the index was created\n",
    "    \"\"\"\n",
    "    is_created = False\n",
    "    try:\n",
    "        if es.indices.exists(index=[index_name]):\n",
    "            es.indices.delete(index=[index_name], ignore=[404])\n",
    "        es.indices.create(index=index_name, settings=settings)\n",
    "        is_created = True\n",
    "    except Exception as ex:\n",
    "        print(str(ex))\n",
    "    return is_created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index settings\n",
    "settings_basic = {\n",
    "        \"number_of_shards\": 4,\n",
    "        \"number_of_replicas\": 2,\n",
    "        \"analysis\": {\n",
    "            \"analyzer\": {\"std_english\": {\"type\": \"standard\", \"stopwords\": \"_english_\" }}\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConnectionError([Errno 2] No such file or directory) caused by: SSLError([Errno 2] No such file or directory)\n",
      "Index creation: False\n"
     ]
    }
   ],
   "source": [
    "#connect to the local elasticsearch node and authenticate\n",
    "es = Elasticsearch(hosts=[ES_ENDPOINT], ca_certs=path_to_ca_certificates, basic_auth=(USER, PWD))\n",
    "#create an index\n",
    "is_created = create_index(es, index_name, settings=settings_basic)\n",
    "print(f'Index creation: {is_created}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loops over the first 10 documents\n",
    "for i, doc in zip(doc_ids[0:10], docs[0:10]):\n",
    "    #index the documents with corresponding ids\n",
    "    res = es.index(index=index_name, id=i, document=doc)\n",
    "    print(res)\n",
    "# see also the bulk functions for importing under: elasticsearch.helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = [\n",
    "  {\n",
    "    \"_index\": index_name,\n",
    "    \"_id\": doc_id,\n",
    "    \"_source\": doc\n",
    "  }\n",
    "  for doc_id, doc in list(zip(doc_ids, docs))\n",
    "]\n",
    "\n",
    "# send actions in bulk (the API takes care of chunking them optimally)\n",
    "bulk(es, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get settings info of the selected index\n",
    "es.indices.get_settings(index=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve a document with a given ID\n",
    "es.get(index=index_name, id=doc_ids[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is how you would delete the index\n",
    "es.indices.delete(index=index_name, ignore=404)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elasticsearch with python cURL (Requests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Elastic:\n",
    "    \"\"\"\n",
    "    A convenience object to send HTTP requests to Elasticsearch\n",
    "    \"\"\"\n",
    "    def __init__(self, endpoint, username, password, path_to_ca_certificates):\n",
    "        \"\"\"\n",
    "        @param endpoint: the URL of the Elasticsearch instance\n",
    "        @param username: the Elasticsearch username \n",
    "        @param password: the Elasticsearch password\n",
    "        \"\"\"\n",
    "        self.header = {'Content-Type': 'application/json', 'charset':'UTF-8'}\n",
    "        #self.header={'Content-Type': '--data-binary application/x-ndjson'}\n",
    "        self.endpoint = endpoint\n",
    "        self.username = username\n",
    "        self.password = password\n",
    "        self.path_to_ca_certificates = path_to_ca_certificates\n",
    "        self.methods_mapping = {'get': requests.get, \n",
    "                                'put':requests.put, \n",
    "                                'post':requests.post, \n",
    "                                'delete':requests.delete}\n",
    "        \n",
    "    def curl(self, method, handle, json=None):\n",
    "        \"\"\"\n",
    "        Sends an HTTP request to the Elasticsearch instance\n",
    "        @param method: can be 'get', 'put', 'post', 'delete'\n",
    "        @param handle: the API handle to be appended to the Elasticsearch url\n",
    "        @param json: the json payload of the HTTP request\n",
    "        \"\"\"\n",
    "        http_method = self.methods_mapping[method.lower()]\n",
    "        r = http_method(f'{self.endpoint}/{handle}', auth=HTTPBasicAuth(USER, PWD), \n",
    "                        headers=self.header, json=json,\n",
    "                        verify = self.path_to_ca_certificates)\n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = Elastic(ES_ENDPOINT, USER, PWD, path_to_ca_certificates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create another index jsut as an example. in the following, we will keep using the book index\n",
    "# created using the Elasticsearch API\n",
    "\n",
    "create_index_json={\n",
    "  \"mappings\" : {\n",
    "      \"properties\" : {\n",
    "        \"author_name\" : {\n",
    "          \"type\" : \"text\"\n",
    "        },\n",
    "        \"country\" : {\n",
    "          \"type\" : \"keyword\"\n",
    "        },\n",
    "        \"language\" : {\n",
    "          \"type\" : \"keyword\"\n",
    "        },\n",
    "        \"title\" : {\n",
    "          \"type\" : \"text\"\n",
    "        },\n",
    "        \"year\" : {\n",
    "          \"type\" : \"long\"\n",
    "        }\n",
    "      }\n",
    "  },\n",
    "  \"settings\": {\n",
    "    \"number_of_shards\": 4, \n",
    "    \"number_of_replicas\": 2, \n",
    "    \"index.max_result_window\": 20000,\n",
    "    \"index\" : {\n",
    "        \"similarity\" : {\n",
    "          \"default\" : {\n",
    "            \"type\" : \"BM25\", \"b\": 0.75, \"k1\": 1.2\n",
    "          }\n",
    "        }\n",
    "    },\n",
    "    \"analysis\": {\n",
    "      \"analyzer\": {\n",
    "        \"std_english\": {\"type\": \"standard\", \"stopwords\": \"_english_\" }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "# create an index\n",
    "r = e.curl('put', index_name, json=create_index_json)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the index details and settings\n",
    "r = e.curl('get', index_name)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deactivate refresh in preparation of data indexing\n",
    "r = e.curl('put', 'books/_settings', {'index' : {'refresh_interval' : -1}})\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index documents with their individual ids (use bulk below for speedup)\n",
    "for doc_id, doc in list(zip(doc_ids, docs))[0:10]:\n",
    "    r = e.curl('post', f'books/_doc/{doc_id}', json=doc)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bulk indexing (via official API)\n",
    "\n",
    "#connect to the local elasticsearch node and authenticate\n",
    "es = Elasticsearch([ES_ENDPOINT], ca_certs=path_to_ca_certificates, basic_auth=(USER, PWD))\n",
    "\n",
    "actions = [\n",
    "  {\n",
    "    \"_index\": index_name,\n",
    "    \"_id\": doc_id,\n",
    "    \"_source\": doc\n",
    "  }\n",
    "  for doc_id, doc in list(zip(doc_ids, docs))\n",
    "]\n",
    "\n",
    "# send actions in bulk (the API takes care of chunking them optimally)\n",
    "bulk(es, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the refresh interval to 2 seconds\n",
    "r = e.curl('put', 'books/_settings', {'index' : {'refresh_interval' : '2s'}})\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = e.curl('get', f'books/_doc/{doc_ids[42]}')\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is how you would delete the index\n",
    "r = e.curl('delete', 'books')\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search queries [EXERCISES]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Empty query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# empty query\n",
    "r = e.curl('get', f'books/_search')\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregation query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "EXERCISE A: \n",
    "execute an aggregation query to count the number of books writte in each country\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full-text query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "EXERCISE B: \n",
    "execute a full-text query for the query \"love magic\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exact match query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "EXERCISE C: \n",
    "execute an exact-match query for the query \"magic love\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-field full-text query with field boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "EXERCISE D: \n",
    "Execute a query that searches both on tile and author\n",
    "Weights the importance of matches on the author field twice as much as matches on the title\n",
    "Sse \"shakespeare\" as query term\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining different queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "EXERCISE E:\n",
    "execute a *single* boolean query returning books that:\n",
    "- have the \"queen mary\" in the title and were written in England\n",
    "- should NOT have been published in the range of years [1850-1913]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fuzzy queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "EXERCISE F:\n",
    "execute a fuzzy query for the query \"comander\" with at most 50 expansions \n",
    "and considering transpositions\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get TF of terms in document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "EXERCISE G:\n",
    "get the term frequencies (in the title) of document with id = 4200\n",
    "consider only words with a minimum length of 4 and a minimum term frequency of 2\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION TO EXERCISE A\n",
    "\n",
    "# aggregation query\n",
    "query = {\n",
    "    \"aggregations\": {\n",
    "        \"by_category\": {\n",
    "            \"terms\": {\n",
    "                \"field\": \"country\",\n",
    "                \"size\":100\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "r = e.curl('get', f'books/_search', query)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION TO EXERCISE B\n",
    "\n",
    "# full-text query\n",
    "query = {\n",
    "    \"query\": {\n",
    "        \"match\": {\n",
    "            \"title\": {\n",
    "                \"query\": \"love magic\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "r = e.curl('get', f'books/_search', query)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION TO EXERCISE C\n",
    "\n",
    "# exact match query\n",
    "query = {\n",
    "  \"query\": {\n",
    "    \"match_phrase\": {\n",
    "      \"title\": {\n",
    "        \"query\": \"magic love\"\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "r = e.curl('get', f'books/_search', query)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION TO EXERCISE D\n",
    "\n",
    "# Full text query, multiple fields with boosting\n",
    "query = {\n",
    "\"query\": {\n",
    "    \"multi_match\": {\n",
    "            \"query\": \"shakespeare\",\n",
    "            \"fields\": [\"title\", \"author_name^2\"],\n",
    "            \"type\": \"phrase\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "r = e.curl('get', f'books/_search', query)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION TO EXERCISE E\n",
    "\n",
    "# One or more queries can be specified in each of the clauses\n",
    "# All the clauses are optional\n",
    "# MUST: A document must match all of the queries\n",
    "# MUST_NOT: A document must not match any of the queries\n",
    "# SHOULD: A document does not have to match the queries, but it is considered more relevant if it does\n",
    "# FILTER: Filters with yes/no categories\n",
    "query = {\n",
    "  \"size\" : 100,\n",
    "  \"query\": {\n",
    "    \"bool\": {\n",
    "      \"must\": [\n",
    "        {\n",
    "          \"match\": {\n",
    "                \"title\": \"queen mary\"\n",
    "          }\n",
    "        },\n",
    "        {\n",
    "          \"match\": {\n",
    "              \"country\": \"England\"\n",
    "          }\n",
    "        }\n",
    "      ],\n",
    "      \"must_not\": [\n",
    "        {\n",
    "          \"range\": {\n",
    "            \"year\": {\n",
    "                \"gte\": 1850,\n",
    "                \"lte\": 1913\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  }\n",
    "}\n",
    "r = e.curl('get', f'books/_search', query)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION TO EXERCISE F\n",
    "\n",
    "query ={\n",
    "  \"query\": {\n",
    "    \"fuzzy\": {\n",
    "      \"title\": {\n",
    "        \"value\": \"comander\",\n",
    "        \"fuzziness\": \"AUTO\",\n",
    "        \"max_expansions\": 50,\n",
    "        \"prefix_length\": 0,\n",
    "        \"transpositions\": True,\n",
    "        \"rewrite\": \"constant_score\"\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "r = e.curl('get', f'books/_search', query)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION TO EXERCISE G\n",
    "\n",
    "# https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-termvectors.html\n",
    "query = {\n",
    "    \"fields\" : [\"title\"],\n",
    "    \"term_statistics\" : True,\n",
    "    \"field_statistics\" : True,\n",
    "    \"positions\": True,\n",
    "    \"filter\": {\n",
    "        \"min_word_length\": 4,\n",
    "        \"min_term_freq\" : 2\n",
    "  }\n",
    "}\n",
    "#r = e.curl('get', f'books/_doc/{doc_ids[4200]}')\n",
    "r = e.curl('get', f'books/_termvectors/{doc_ids[4200]}', query)\n",
    "r.json()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-in-production",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "293.396px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "83929ffd1ad749d46bf46224d7a1f235b1a3279e6736dc3a23f1c3927642f57f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
