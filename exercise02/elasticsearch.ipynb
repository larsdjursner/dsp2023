{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 13, 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "from elasticsearch import Elasticsearch\n",
    "import elasticsearch\n",
    "from elasticsearch.helpers import bulk\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "\n",
    "print(elasticsearch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!! CUSTOMIZE THIS SECTION WITH YOUR CREDENTIALS !!!\n",
    "\n",
    "USER = 'elastic'\n",
    "PWD = os.getenv(\"ELASTIC_PASSWORD\")\n",
    "index_name = 'books'\n",
    "ES_ENDPOINT = 'https://localhost:9200'\n",
    "\n",
    "path_to_ca_certificates = '../certs/ca/ca.crt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_name</th>\n",
       "      <th>title</th>\n",
       "      <th>country</th>\n",
       "      <th>language</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14602826</th>\n",
       "      <td>Yearsley, Ann</td>\n",
       "      <td>Poems on several occasions</td>\n",
       "      <td>England</td>\n",
       "      <td>English</td>\n",
       "      <td>1786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14602830</th>\n",
       "      <td>A, T.</td>\n",
       "      <td>A Satyr against Vertue. (A poem: supposed to b...</td>\n",
       "      <td>England</td>\n",
       "      <td>English</td>\n",
       "      <td>1679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14602831</th>\n",
       "      <td>A, T.</td>\n",
       "      <td>The Aeronaut, a poem; founded almost entirely,...</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>English</td>\n",
       "      <td>1816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14602832</th>\n",
       "      <td>Albert, Prince Consort, consort of Victoria, Q...</td>\n",
       "      <td>The Prince Albert, a poem</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>English</td>\n",
       "      <td>1868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14602833</th>\n",
       "      <td>Anslow, Robert</td>\n",
       "      <td>The Defeat of the Spanish Armada, A.D. 1588. A...</td>\n",
       "      <td>England</td>\n",
       "      <td>English</td>\n",
       "      <td>1888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                author_name  \\\n",
       "id                                                            \n",
       "14602826                                      Yearsley, Ann   \n",
       "14602830                                              A, T.   \n",
       "14602831                                              A, T.   \n",
       "14602832  Albert, Prince Consort, consort of Victoria, Q...   \n",
       "14602833                                     Anslow, Robert   \n",
       "\n",
       "                                                      title  country language  \\\n",
       "id                                                                              \n",
       "14602826                         Poems on several occasions  England  English   \n",
       "14602830  A Satyr against Vertue. (A poem: supposed to b...  England  English   \n",
       "14602831  The Aeronaut, a poem; founded almost entirely,...  Ireland  English   \n",
       "14602832                          The Prince Albert, a poem  Ireland  English   \n",
       "14602833  The Defeat of the Spanish Armada, A.D. 1588. A...  England  English   \n",
       "\n",
       "          year  \n",
       "id              \n",
       "14602826  1786  \n",
       "14602830  1679  \n",
       "14602831  1816  \n",
       "14602832  1868  \n",
       "14602833  1888  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('books.csv')\n",
    "df = df.set_index('id')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14602826\n",
      "{'author_name': 'Yearsley, Ann', 'title': 'Poems on several occasions', 'country': 'England', 'language': 'English', 'year': 1786}\n"
     ]
    }
   ],
   "source": [
    "#transform dataframe into json format\n",
    "docs = df.to_dict(orient='records')\n",
    "doc_ids = df.index\n",
    "print(doc_ids[0])\n",
    "print(docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Elasticsearch Python wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index(es, index_name, settings=None):\n",
    "    \"\"\"\n",
    "    Create an Elasticsearch index\n",
    "    @param es: an Elasticsearch object\n",
    "    @param index_name: the name of the new index to be created\n",
    "    @param settings: the index settings\n",
    "    @return whether the index was created\n",
    "    \"\"\"\n",
    "    is_created = False\n",
    "    try:\n",
    "        if es.indices.exists(index=[index_name]):\n",
    "            es.indices.delete(index=[index_name], ignore=[404])\n",
    "        es.indices.create(index=index_name, settings=settings)\n",
    "        is_created = True\n",
    "    except Exception as ex:\n",
    "        print(str(ex))\n",
    "    return is_created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index settings\n",
    "settings_basic = {\n",
    "        \"number_of_shards\": 4,\n",
    "        \"number_of_replicas\": 2,\n",
    "        \"analysis\": {\n",
    "            \"analyzer\": {\"std_english\": {\"type\": \"standard\", \"stopwords\": \"_english_\" }}\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AuthenticationException(401, '')\n",
      "Index creation: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ladr/anaconda3/envs/data-in-production/lib/python3.9/site-packages/elasticsearch/connection/http_urllib3.py:209: UserWarning: Connecting to https://localhost:9200 using SSL with verify_certs=False is insecure.\n",
      "  warnings.warn(\n",
      "/home/ladr/anaconda3/envs/data-in-production/lib/python3.9/site-packages/urllib3/connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'localhost'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#connect to the local elasticsearch node and authenticate\n",
    "es = Elasticsearch(hosts=[ES_ENDPOINT], ca_certs=path_to_ca_certificates, basic_auth=(USER, PWD))\n",
    "#create an index\n",
    "is_created = create_index(es, index_name, settings=settings_basic)\n",
    "print(f'Index creation: {is_created}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "index() got an unexpected keyword argument 'document'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[85], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#loops over the first 10 documents\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m i, doc \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(doc_ids[\u001b[39m0\u001b[39m:\u001b[39m10\u001b[39m], docs[\u001b[39m0\u001b[39m:\u001b[39m10\u001b[39m]):\n\u001b[1;32m      3\u001b[0m     \u001b[39m#index the documents with corresponding ids\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     res \u001b[39m=\u001b[39m es\u001b[39m.\u001b[39;49mindex(index\u001b[39m=\u001b[39;49mindex_name, \u001b[39mid\u001b[39;49m\u001b[39m=\u001b[39;49mi, document\u001b[39m=\u001b[39;49mdoc)\n\u001b[1;32m      5\u001b[0m     \u001b[39mprint\u001b[39m(res)\n",
      "File \u001b[0;32m~/anaconda3/envs/data-in-production/lib/python3.9/site-packages/elasticsearch/client/utils.py:168\u001b[0m, in \u001b[0;36mquery_params.<locals>._wrapper.<locals>._wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[39mif\u001b[39;00m p \u001b[39min\u001b[39;00m kwargs:\n\u001b[1;32m    167\u001b[0m         params[p] \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(p)\n\u001b[0;32m--> 168\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, params\u001b[39m=\u001b[39;49mparams, headers\u001b[39m=\u001b[39;49mheaders, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mTypeError\u001b[0m: index() got an unexpected keyword argument 'document'"
     ]
    }
   ],
   "source": [
    "#loops over the first 10 documents\n",
    "for i, doc in zip(doc_ids[0:10], docs[0:10]):\n",
    "    #index the documents with corresponding ids\n",
    "    res = es.index(index=index_name, id=i, document=doc)\n",
    "    print(res)\n",
    "# see also the bulk functions for importing under: elasticsearch.helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ladr/anaconda3/envs/data-in-production/lib/python3.9/site-packages/urllib3/connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'localhost'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AuthenticationException",
     "evalue": "AuthenticationException(401, 'security_exception', 'missing authentication credentials for REST request [/_bulk]')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationException\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[86], line 11\u001b[0m\n\u001b[1;32m      1\u001b[0m actions \u001b[39m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m   {\n\u001b[1;32m      3\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m_index\u001b[39m\u001b[39m\"\u001b[39m: index_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[39mfor\u001b[39;00m doc_id, doc \u001b[39min\u001b[39;00m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(doc_ids, docs))\n\u001b[1;32m      8\u001b[0m ]\n\u001b[1;32m     10\u001b[0m \u001b[39m# send actions in bulk (the API takes care of chunking them optimally)\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m bulk(es, actions)\n",
      "File \u001b[0;32m~/anaconda3/envs/data-in-production/lib/python3.9/site-packages/elasticsearch/helpers/actions.py:410\u001b[0m, in \u001b[0;36mbulk\u001b[0;34m(client, actions, stats_only, ignore_status, *args, **kwargs)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[39m# make streaming_bulk yield successful results so we can count them\u001b[39;00m\n\u001b[1;32m    409\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39myield_ok\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 410\u001b[0m \u001b[39mfor\u001b[39;00m ok, item \u001b[39min\u001b[39;00m streaming_bulk(\n\u001b[1;32m    411\u001b[0m     client, actions, ignore_status\u001b[39m=\u001b[39mignore_status, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    412\u001b[0m ):\n\u001b[1;32m    413\u001b[0m     \u001b[39m# go through request-response pairs and detect failures\u001b[39;00m\n\u001b[1;32m    414\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ok:\n\u001b[1;32m    415\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m stats_only:\n",
      "File \u001b[0;32m~/anaconda3/envs/data-in-production/lib/python3.9/site-packages/elasticsearch/helpers/actions.py:329\u001b[0m, in \u001b[0;36mstreaming_bulk\u001b[0;34m(client, actions, chunk_size, max_chunk_bytes, raise_on_error, expand_action_callback, raise_on_exception, max_retries, initial_backoff, max_backoff, yield_ok, ignore_status, *args, **kwargs)\u001b[0m\n\u001b[1;32m    326\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39mmin\u001b[39m(max_backoff, initial_backoff \u001b[39m*\u001b[39m \u001b[39m2\u001b[39m \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m (attempt \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)))\n\u001b[1;32m    328\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 329\u001b[0m     \u001b[39mfor\u001b[39;00m data, (ok, info) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\n\u001b[1;32m    330\u001b[0m         bulk_data,\n\u001b[1;32m    331\u001b[0m         _process_bulk_chunk(\n\u001b[1;32m    332\u001b[0m             client,\n\u001b[1;32m    333\u001b[0m             bulk_actions,\n\u001b[1;32m    334\u001b[0m             bulk_data,\n\u001b[1;32m    335\u001b[0m             raise_on_exception,\n\u001b[1;32m    336\u001b[0m             raise_on_error,\n\u001b[1;32m    337\u001b[0m             ignore_status,\n\u001b[1;32m    338\u001b[0m             \u001b[39m*\u001b[39margs,\n\u001b[1;32m    339\u001b[0m             \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    340\u001b[0m         ),\n\u001b[1;32m    341\u001b[0m     ):\n\u001b[1;32m    343\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ok:\n\u001b[1;32m    344\u001b[0m             action, info \u001b[39m=\u001b[39m info\u001b[39m.\u001b[39mpopitem()\n",
      "File \u001b[0;32m~/anaconda3/envs/data-in-production/lib/python3.9/site-packages/elasticsearch/helpers/actions.py:256\u001b[0m, in \u001b[0;36m_process_bulk_chunk\u001b[0;34m(client, bulk_actions, bulk_data, raise_on_exception, raise_on_error, ignore_status, *args, **kwargs)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    250\u001b[0m     gen \u001b[39m=\u001b[39m _process_bulk_chunk_success(\n\u001b[1;32m    251\u001b[0m         resp\u001b[39m=\u001b[39mresp,\n\u001b[1;32m    252\u001b[0m         bulk_data\u001b[39m=\u001b[39mbulk_data,\n\u001b[1;32m    253\u001b[0m         ignore_status\u001b[39m=\u001b[39mignore_status,\n\u001b[1;32m    254\u001b[0m         raise_on_error\u001b[39m=\u001b[39mraise_on_error,\n\u001b[1;32m    255\u001b[0m     )\n\u001b[0;32m--> 256\u001b[0m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m gen:\n\u001b[1;32m    257\u001b[0m     \u001b[39myield\u001b[39;00m item\n",
      "File \u001b[0;32m~/anaconda3/envs/data-in-production/lib/python3.9/site-packages/elasticsearch/helpers/actions.py:195\u001b[0m, in \u001b[0;36m_process_bulk_chunk_error\u001b[0;34m(error, bulk_data, ignore_status, raise_on_exception, raise_on_error)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_process_bulk_chunk_error\u001b[39m(\n\u001b[1;32m    191\u001b[0m     error, bulk_data, ignore_status, raise_on_exception\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, raise_on_error\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    192\u001b[0m ):\n\u001b[1;32m    193\u001b[0m     \u001b[39m# default behavior - just propagate exception\u001b[39;00m\n\u001b[1;32m    194\u001b[0m     \u001b[39mif\u001b[39;00m raise_on_exception \u001b[39mand\u001b[39;00m error\u001b[39m.\u001b[39mstatus_code \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ignore_status:\n\u001b[0;32m--> 195\u001b[0m         \u001b[39mraise\u001b[39;00m error\n\u001b[1;32m    197\u001b[0m     \u001b[39m# if we are not propagating, mark all actions in current chunk as failed\u001b[39;00m\n\u001b[1;32m    198\u001b[0m     err_message \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(error)\n",
      "File \u001b[0;32m~/anaconda3/envs/data-in-production/lib/python3.9/site-packages/elasticsearch/helpers/actions.py:240\u001b[0m, in \u001b[0;36m_process_bulk_chunk\u001b[0;34m(client, bulk_actions, bulk_data, raise_on_exception, raise_on_error, ignore_status, *args, **kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m     ignore_status \u001b[39m=\u001b[39m (ignore_status,)\n\u001b[1;32m    238\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    239\u001b[0m     \u001b[39m# send the actual request\u001b[39;00m\n\u001b[0;32m--> 240\u001b[0m     resp \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49mbulk(\u001b[39m\"\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(bulk_actions) \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    241\u001b[0m \u001b[39mexcept\u001b[39;00m TransportError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    242\u001b[0m     gen \u001b[39m=\u001b[39m _process_bulk_chunk_error(\n\u001b[1;32m    243\u001b[0m         error\u001b[39m=\u001b[39me,\n\u001b[1;32m    244\u001b[0m         bulk_data\u001b[39m=\u001b[39mbulk_data,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m         raise_on_error\u001b[39m=\u001b[39mraise_on_error,\n\u001b[1;32m    248\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/data-in-production/lib/python3.9/site-packages/elasticsearch/client/utils.py:168\u001b[0m, in \u001b[0;36mquery_params.<locals>._wrapper.<locals>._wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[39mif\u001b[39;00m p \u001b[39min\u001b[39;00m kwargs:\n\u001b[1;32m    167\u001b[0m         params[p] \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(p)\n\u001b[0;32m--> 168\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, params\u001b[39m=\u001b[39;49mparams, headers\u001b[39m=\u001b[39;49mheaders, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/data-in-production/lib/python3.9/site-packages/elasticsearch/client/__init__.py:463\u001b[0m, in \u001b[0;36mElasticsearch.bulk\u001b[0;34m(self, body, index, doc_type, params, headers)\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mEmpty value passed for a required argument \u001b[39m\u001b[39m'\u001b[39m\u001b[39mbody\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    462\u001b[0m body \u001b[39m=\u001b[39m _bulk_body(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransport\u001b[39m.\u001b[39mserializer, body)\n\u001b[0;32m--> 463\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransport\u001b[39m.\u001b[39;49mperform_request(\n\u001b[1;32m    464\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mPOST\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    465\u001b[0m     _make_path(index, doc_type, \u001b[39m\"\u001b[39;49m\u001b[39m_bulk\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    466\u001b[0m     params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    467\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    468\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    469\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/data-in-production/lib/python3.9/site-packages/elasticsearch/transport.py:415\u001b[0m, in \u001b[0;36mTransport.perform_request\u001b[0;34m(self, method, url, headers, params, body)\u001b[0m\n\u001b[1;32m    413\u001b[0m             \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    414\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m         \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    417\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[39m# connection didn't fail, confirm it's live status\u001b[39;00m\n\u001b[1;32m    419\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconnection_pool\u001b[39m.\u001b[39mmark_live(connection)\n",
      "File \u001b[0;32m~/anaconda3/envs/data-in-production/lib/python3.9/site-packages/elasticsearch/transport.py:381\u001b[0m, in \u001b[0;36mTransport.perform_request\u001b[0;34m(self, method, url, headers, params, body)\u001b[0m\n\u001b[1;32m    378\u001b[0m connection \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_connection()\n\u001b[1;32m    380\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     status, headers_response, data \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mperform_request(\n\u001b[1;32m    382\u001b[0m         method,\n\u001b[1;32m    383\u001b[0m         url,\n\u001b[1;32m    384\u001b[0m         params,\n\u001b[1;32m    385\u001b[0m         body,\n\u001b[1;32m    386\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    387\u001b[0m         ignore\u001b[39m=\u001b[39;49mignore,\n\u001b[1;32m    388\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    389\u001b[0m     )\n\u001b[1;32m    391\u001b[0m \u001b[39mexcept\u001b[39;00m TransportError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    392\u001b[0m     \u001b[39mif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mHEAD\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m e\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m404\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/data-in-production/lib/python3.9/site-packages/elasticsearch/connection/http_urllib3.py:277\u001b[0m, in \u001b[0;36mUrllib3HttpConnection.perform_request\u001b[0;34m(self, method, url, params, body, timeout, ignore, headers)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mstatus \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m) \u001b[39mand\u001b[39;00m response\u001b[39m.\u001b[39mstatus \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ignore:\n\u001b[1;32m    274\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog_request_fail(\n\u001b[1;32m    275\u001b[0m         method, full_url, url, orig_body, duration, response\u001b[39m.\u001b[39mstatus, raw_data\n\u001b[1;32m    276\u001b[0m     )\n\u001b[0;32m--> 277\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_error(response\u001b[39m.\u001b[39;49mstatus, raw_data)\n\u001b[1;32m    279\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog_request_success(\n\u001b[1;32m    280\u001b[0m     method, full_url, url, orig_body, response\u001b[39m.\u001b[39mstatus, raw_data, duration\n\u001b[1;32m    281\u001b[0m )\n\u001b[1;32m    283\u001b[0m \u001b[39mreturn\u001b[39;00m response\u001b[39m.\u001b[39mstatus, response\u001b[39m.\u001b[39mgetheaders(), raw_data\n",
      "File \u001b[0;32m~/anaconda3/envs/data-in-production/lib/python3.9/site-packages/elasticsearch/connection/base.py:330\u001b[0m, in \u001b[0;36mConnection._raise_error\u001b[0;34m(self, status_code, raw_data)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    328\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\u001b[39m\"\u001b[39m\u001b[39mUndecodable raw error response from server: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, err)\n\u001b[0;32m--> 330\u001b[0m \u001b[39mraise\u001b[39;00m HTTP_EXCEPTIONS\u001b[39m.\u001b[39mget(status_code, TransportError)(\n\u001b[1;32m    331\u001b[0m     status_code, error_message, additional_info\n\u001b[1;32m    332\u001b[0m )\n",
      "\u001b[0;31mAuthenticationException\u001b[0m: AuthenticationException(401, 'security_exception', 'missing authentication credentials for REST request [/_bulk]')"
     ]
    }
   ],
   "source": [
    "actions = [\n",
    "  {\n",
    "    \"_index\": index_name,\n",
    "    \"_id\": doc_id,\n",
    "    \"_source\": doc\n",
    "  }\n",
    "  for doc_id, doc in list(zip(doc_ids, docs))\n",
    "]\n",
    "\n",
    "# send actions in bulk (the API takes care of chunking them optimally)\n",
    "bulk(es, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get settings info of the selected index\n",
    "es.indices.get_settings(index=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve a document with a given ID\n",
    "es.get(index=index_name, id=doc_ids[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is how you would delete the index\n",
    "es.indices.delete(index=index_name, ignore=404)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elasticsearch with python cURL (Requests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Elastic:\n",
    "    \"\"\"\n",
    "    A convenience object to send HTTP requests to Elasticsearch\n",
    "    \"\"\"\n",
    "    def __init__(self, endpoint, username, password, path_to_ca_certificates):\n",
    "        \"\"\"\n",
    "        @param endpoint: the URL of the Elasticsearch instance\n",
    "        @param username: the Elasticsearch username \n",
    "        @param password: the Elasticsearch password\n",
    "        \"\"\"\n",
    "        self.header = {'Content-Type': 'application/json', 'charset':'UTF-8'}\n",
    "        #self.header={'Content-Type': '--data-binary application/x-ndjson'}\n",
    "        self.endpoint = endpoint\n",
    "        self.username = username\n",
    "        self.password = password\n",
    "        self.path_to_ca_certificates = path_to_ca_certificates\n",
    "        self.methods_mapping = {'get': requests.get, \n",
    "                                'put':requests.put, \n",
    "                                'post':requests.post, \n",
    "                                'delete':requests.delete}\n",
    "        \n",
    "    def curl(self, method, handle, json=None):\n",
    "        \"\"\"\n",
    "        Sends an HTTP request to the Elasticsearch instance\n",
    "        @param method: can be 'get', 'put', 'post', 'delete'\n",
    "        @param handle: the API handle to be appended to the Elasticsearch url\n",
    "        @param json: the json payload of the HTTP request\n",
    "        \"\"\"\n",
    "        http_method = self.methods_mapping[method.lower()]\n",
    "        r = http_method(f'{self.endpoint}/{handle}', auth=HTTPBasicAuth(USER, PWD), \n",
    "                        headers=self.header, json=json,\n",
    "                        verify = self.path_to_ca_certificates)\n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = Elastic(ES_ENDPOINT, USER, PWD, path_to_ca_certificates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'books'}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create another index jsut as an example. in the following, we will keep using the book index\n",
    "# created using the Elasticsearch API\n",
    "\n",
    "create_index_json={\n",
    "  \"mappings\" : {\n",
    "      \"properties\" : {\n",
    "        \"author_name\" : {\n",
    "          \"type\" : \"text\"\n",
    "        },\n",
    "        \"country\" : {\n",
    "          \"type\" : \"keyword\"\n",
    "        },\n",
    "        \"language\" : {\n",
    "          \"type\" : \"keyword\"\n",
    "        },\n",
    "        \"title\" : {\n",
    "          \"type\" : \"text\"\n",
    "        },\n",
    "        \"year\" : {\n",
    "          \"type\" : \"long\"\n",
    "        }\n",
    "      }\n",
    "  },\n",
    "  \"settings\": {\n",
    "    \"number_of_shards\": 4, \n",
    "    \"number_of_replicas\": 2, \n",
    "    \"index.max_result_window\": 20000,\n",
    "    \"index\" : {\n",
    "        \"similarity\" : {\n",
    "          \"default\" : {\n",
    "            \"type\" : \"BM25\", \"b\": 0.75, \"k1\": 1.2\n",
    "          }\n",
    "        }\n",
    "    },\n",
    "    \"analysis\": {\n",
    "      \"analyzer\": {\n",
    "        \"std_english\": {\"type\": \"standard\", \"stopwords\": \"_english_\" }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "# create an index\n",
    "r = e.curl('put', index_name, json=create_index_json)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'books': {'aliases': {},\n",
       "  'mappings': {'properties': {'author_name': {'type': 'text'},\n",
       "    'country': {'type': 'keyword'},\n",
       "    'language': {'type': 'keyword'},\n",
       "    'title': {'type': 'text'},\n",
       "    'year': {'type': 'long'}}},\n",
       "  'settings': {'index': {'routing': {'allocation': {'include': {'_tier_preference': 'data_content'}}},\n",
       "    'number_of_shards': '4',\n",
       "    'provided_name': 'books',\n",
       "    'similarity': {'default': {'type': 'BM25', 'b': '0.75', 'k1': '1.2'}},\n",
       "    'max_result_window': '20000',\n",
       "    'creation_date': '1676653218135',\n",
       "    'analysis': {'analyzer': {'std_english': {'type': 'standard',\n",
       "       'stopwords': '_english_'}}},\n",
       "    'number_of_replicas': '2',\n",
       "    'uuid': 'UetcIJTHRMSp7Mv3Lz0mGg',\n",
       "    'version': {'created': '8050399'}}}}}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the index details and settings\n",
    "r = e.curl('get', index_name)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# deactivate refresh in preparation of data indexing\n",
    "r = e.curl('put', 'books/_settings', {'index' : {'refresh_interval' : -1}})\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_index': 'books',\n",
       " '_id': '14602838',\n",
       " '_version': 1,\n",
       " 'result': 'created',\n",
       " '_shards': {'total': 3, 'successful': 1, 'failed': 0},\n",
       " '_seq_no': 2,\n",
       " '_primary_term': 1}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index documents with their individual ids (use bulk below for speedup)\n",
    "for doc_id, doc in list(zip(doc_ids, docs))[0:10]:\n",
    "    r = e.curl('post', f'books/_doc/{doc_id}', json=doc)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationException",
     "evalue": "AuthenticationException(401, 'security_exception', 'missing authentication credentials for REST request [/_bulk]')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationException\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 16\u001b[0m\n\u001b[1;32m      6\u001b[0m actions \u001b[39m=\u001b[39m [\n\u001b[1;32m      7\u001b[0m   {\n\u001b[1;32m      8\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m_index\u001b[39m\u001b[39m\"\u001b[39m: index_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[39mfor\u001b[39;00m doc_id, doc \u001b[39min\u001b[39;00m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(doc_ids, docs))\n\u001b[1;32m     13\u001b[0m ]\n\u001b[1;32m     15\u001b[0m \u001b[39m# send actions in bulk (the API takes care of chunking them optimally)\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m bulk(es, actions)\n",
      "File \u001b[0;32m~/anaconda3/envs/data-in-production/lib/python3.9/site-packages/elasticsearch/helpers/actions.py:410\u001b[0m, in \u001b[0;36mbulk\u001b[0;34m(client, actions, stats_only, ignore_status, *args, **kwargs)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[39m# make streaming_bulk yield successful results so we can count them\u001b[39;00m\n\u001b[1;32m    409\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39myield_ok\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 410\u001b[0m \u001b[39mfor\u001b[39;00m ok, item \u001b[39min\u001b[39;00m streaming_bulk(\n\u001b[1;32m    411\u001b[0m     client, actions, ignore_status\u001b[39m=\u001b[39mignore_status, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    412\u001b[0m ):\n\u001b[1;32m    413\u001b[0m     \u001b[39m# go through request-response pairs and detect failures\u001b[39;00m\n\u001b[1;32m    414\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ok:\n\u001b[1;32m    415\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m stats_only:\n",
      "File \u001b[0;32m~/anaconda3/envs/data-in-production/lib/python3.9/site-packages/elasticsearch/helpers/actions.py:329\u001b[0m, in \u001b[0;36mstreaming_bulk\u001b[0;34m(client, actions, chunk_size, max_chunk_bytes, raise_on_error, expand_action_callback, raise_on_exception, max_retries, initial_backoff, max_backoff, yield_ok, ignore_status, *args, **kwargs)\u001b[0m\n\u001b[1;32m    326\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39mmin\u001b[39m(max_backoff, initial_backoff \u001b[39m*\u001b[39m \u001b[39m2\u001b[39m \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m (attempt \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)))\n\u001b[1;32m    328\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 329\u001b[0m     \u001b[39mfor\u001b[39;00m data, (ok, info) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\n\u001b[1;32m    330\u001b[0m         bulk_data,\n\u001b[1;32m    331\u001b[0m         _process_bulk_chunk(\n\u001b[1;32m    332\u001b[0m             client,\n\u001b[1;32m    333\u001b[0m             bulk_actions,\n\u001b[1;32m    334\u001b[0m             bulk_data,\n\u001b[1;32m    335\u001b[0m             raise_on_exception,\n\u001b[1;32m    336\u001b[0m             raise_on_error,\n\u001b[1;32m    337\u001b[0m             ignore_status,\n\u001b[1;32m    338\u001b[0m             \u001b[39m*\u001b[39margs,\n\u001b[1;32m    339\u001b[0m             \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    340\u001b[0m         ),\n\u001b[1;32m    341\u001b[0m     ):\n\u001b[1;32m    343\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ok:\n\u001b[1;32m    344\u001b[0m             action, info \u001b[39m=\u001b[39m info\u001b[39m.\u001b[39mpopitem()\n",
      "File \u001b[0;32m~/anaconda3/envs/data-in-production/lib/python3.9/site-packages/elasticsearch/helpers/actions.py:256\u001b[0m, in \u001b[0;36m_process_bulk_chunk\u001b[0;34m(client, bulk_actions, bulk_data, raise_on_exception, raise_on_error, ignore_status, *args, **kwargs)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    250\u001b[0m     gen \u001b[39m=\u001b[39m _process_bulk_chunk_success(\n\u001b[1;32m    251\u001b[0m         resp\u001b[39m=\u001b[39mresp,\n\u001b[1;32m    252\u001b[0m         bulk_data\u001b[39m=\u001b[39mbulk_data,\n\u001b[1;32m    253\u001b[0m         ignore_status\u001b[39m=\u001b[39mignore_status,\n\u001b[1;32m    254\u001b[0m         raise_on_error\u001b[39m=\u001b[39mraise_on_error,\n\u001b[1;32m    255\u001b[0m     )\n\u001b[0;32m--> 256\u001b[0m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m gen:\n\u001b[1;32m    257\u001b[0m     \u001b[39myield\u001b[39;00m item\n",
      "File \u001b[0;32m~/anaconda3/envs/data-in-production/lib/python3.9/site-packages/elasticsearch/helpers/actions.py:195\u001b[0m, in \u001b[0;36m_process_bulk_chunk_error\u001b[0;34m(error, bulk_data, ignore_status, raise_on_exception, raise_on_error)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_process_bulk_chunk_error\u001b[39m(\n\u001b[1;32m    191\u001b[0m     error, bulk_data, ignore_status, raise_on_exception\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, raise_on_error\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    192\u001b[0m ):\n\u001b[1;32m    193\u001b[0m     \u001b[39m# default behavior - just propagate exception\u001b[39;00m\n\u001b[1;32m    194\u001b[0m     \u001b[39mif\u001b[39;00m raise_on_exception \u001b[39mand\u001b[39;00m error\u001b[39m.\u001b[39mstatus_code \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ignore_status:\n\u001b[0;32m--> 195\u001b[0m         \u001b[39mraise\u001b[39;00m error\n\u001b[1;32m    197\u001b[0m     \u001b[39m# if we are not propagating, mark all actions in current chunk as failed\u001b[39;00m\n\u001b[1;32m    198\u001b[0m     err_message \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(error)\n",
      "File \u001b[0;32m~/anaconda3/envs/data-in-production/lib/python3.9/site-packages/elasticsearch/helpers/actions.py:240\u001b[0m, in \u001b[0;36m_process_bulk_chunk\u001b[0;34m(client, bulk_actions, bulk_data, raise_on_exception, raise_on_error, ignore_status, *args, **kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m     ignore_status \u001b[39m=\u001b[39m (ignore_status,)\n\u001b[1;32m    238\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    239\u001b[0m     \u001b[39m# send the actual request\u001b[39;00m\n\u001b[0;32m--> 240\u001b[0m     resp \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49mbulk(\u001b[39m\"\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(bulk_actions) \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    241\u001b[0m \u001b[39mexcept\u001b[39;00m TransportError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    242\u001b[0m     gen \u001b[39m=\u001b[39m _process_bulk_chunk_error(\n\u001b[1;32m    243\u001b[0m         error\u001b[39m=\u001b[39me,\n\u001b[1;32m    244\u001b[0m         bulk_data\u001b[39m=\u001b[39mbulk_data,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m         raise_on_error\u001b[39m=\u001b[39mraise_on_error,\n\u001b[1;32m    248\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/data-in-production/lib/python3.9/site-packages/elasticsearch/client/utils.py:168\u001b[0m, in \u001b[0;36mquery_params.<locals>._wrapper.<locals>._wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[39mif\u001b[39;00m p \u001b[39min\u001b[39;00m kwargs:\n\u001b[1;32m    167\u001b[0m         params[p] \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(p)\n\u001b[0;32m--> 168\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, params\u001b[39m=\u001b[39;49mparams, headers\u001b[39m=\u001b[39;49mheaders, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/data-in-production/lib/python3.9/site-packages/elasticsearch/client/__init__.py:463\u001b[0m, in \u001b[0;36mElasticsearch.bulk\u001b[0;34m(self, body, index, doc_type, params, headers)\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mEmpty value passed for a required argument \u001b[39m\u001b[39m'\u001b[39m\u001b[39mbody\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    462\u001b[0m body \u001b[39m=\u001b[39m _bulk_body(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransport\u001b[39m.\u001b[39mserializer, body)\n\u001b[0;32m--> 463\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransport\u001b[39m.\u001b[39;49mperform_request(\n\u001b[1;32m    464\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mPOST\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    465\u001b[0m     _make_path(index, doc_type, \u001b[39m\"\u001b[39;49m\u001b[39m_bulk\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    466\u001b[0m     params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    467\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    468\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    469\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/data-in-production/lib/python3.9/site-packages/elasticsearch/transport.py:415\u001b[0m, in \u001b[0;36mTransport.perform_request\u001b[0;34m(self, method, url, headers, params, body)\u001b[0m\n\u001b[1;32m    413\u001b[0m             \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    414\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m         \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    417\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[39m# connection didn't fail, confirm it's live status\u001b[39;00m\n\u001b[1;32m    419\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconnection_pool\u001b[39m.\u001b[39mmark_live(connection)\n",
      "File \u001b[0;32m~/anaconda3/envs/data-in-production/lib/python3.9/site-packages/elasticsearch/transport.py:381\u001b[0m, in \u001b[0;36mTransport.perform_request\u001b[0;34m(self, method, url, headers, params, body)\u001b[0m\n\u001b[1;32m    378\u001b[0m connection \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_connection()\n\u001b[1;32m    380\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     status, headers_response, data \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mperform_request(\n\u001b[1;32m    382\u001b[0m         method,\n\u001b[1;32m    383\u001b[0m         url,\n\u001b[1;32m    384\u001b[0m         params,\n\u001b[1;32m    385\u001b[0m         body,\n\u001b[1;32m    386\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    387\u001b[0m         ignore\u001b[39m=\u001b[39;49mignore,\n\u001b[1;32m    388\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    389\u001b[0m     )\n\u001b[1;32m    391\u001b[0m \u001b[39mexcept\u001b[39;00m TransportError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    392\u001b[0m     \u001b[39mif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mHEAD\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m e\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m404\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/data-in-production/lib/python3.9/site-packages/elasticsearch/connection/http_urllib3.py:277\u001b[0m, in \u001b[0;36mUrllib3HttpConnection.perform_request\u001b[0;34m(self, method, url, params, body, timeout, ignore, headers)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mstatus \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m) \u001b[39mand\u001b[39;00m response\u001b[39m.\u001b[39mstatus \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ignore:\n\u001b[1;32m    274\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog_request_fail(\n\u001b[1;32m    275\u001b[0m         method, full_url, url, orig_body, duration, response\u001b[39m.\u001b[39mstatus, raw_data\n\u001b[1;32m    276\u001b[0m     )\n\u001b[0;32m--> 277\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_error(response\u001b[39m.\u001b[39;49mstatus, raw_data)\n\u001b[1;32m    279\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog_request_success(\n\u001b[1;32m    280\u001b[0m     method, full_url, url, orig_body, response\u001b[39m.\u001b[39mstatus, raw_data, duration\n\u001b[1;32m    281\u001b[0m )\n\u001b[1;32m    283\u001b[0m \u001b[39mreturn\u001b[39;00m response\u001b[39m.\u001b[39mstatus, response\u001b[39m.\u001b[39mgetheaders(), raw_data\n",
      "File \u001b[0;32m~/anaconda3/envs/data-in-production/lib/python3.9/site-packages/elasticsearch/connection/base.py:330\u001b[0m, in \u001b[0;36mConnection._raise_error\u001b[0;34m(self, status_code, raw_data)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    328\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\u001b[39m\"\u001b[39m\u001b[39mUndecodable raw error response from server: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, err)\n\u001b[0;32m--> 330\u001b[0m \u001b[39mraise\u001b[39;00m HTTP_EXCEPTIONS\u001b[39m.\u001b[39mget(status_code, TransportError)(\n\u001b[1;32m    331\u001b[0m     status_code, error_message, additional_info\n\u001b[1;32m    332\u001b[0m )\n",
      "\u001b[0;31mAuthenticationException\u001b[0m: AuthenticationException(401, 'security_exception', 'missing authentication credentials for REST request [/_bulk]')"
     ]
    }
   ],
   "source": [
    "# bulk indexing (via official API)\n",
    "\n",
    "#connect to the local elasticsearch node and authenticate\n",
    "es = Elasticsearch([ES_ENDPOINT], ca_certs=path_to_ca_certificates, basic_auth=(USER, PWD))\n",
    "\n",
    "actions = [\n",
    "  {\n",
    "    \"_index\": index_name,\n",
    "    \"_id\": doc_id,\n",
    "    \"_source\": doc\n",
    "  }\n",
    "  for doc_id, doc in list(zip(doc_ids, docs))\n",
    "]\n",
    "\n",
    "# send actions in bulk (the API takes care of chunking them optimally)\n",
    "bulk(es, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'e' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10678/1387967130.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# reset the refresh interval to 2 seconds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'put'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'books/_settings'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'index'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'refresh_interval'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m'2s'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'e' is not defined"
     ]
    }
   ],
   "source": [
    "# reset the refresh interval to 2 seconds\n",
    "r = e.curl('put', 'books/_settings', {'index' : {'refresh_interval' : '2s'}})\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = e.curl('get', f'books/_doc/{doc_ids[42]}')\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is how you would delete the index\n",
    "r = e.curl('delete', 'books')\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search queries [EXERCISES]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Empty query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# empty query\n",
    "r = e.curl('get', f'books/_search')\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregation query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "EXERCISE A: \n",
    "execute an aggregation query to count the number of books writte in each country\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full-text query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "EXERCISE B: \n",
    "execute a full-text query for the query \"love magic\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exact match query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "EXERCISE C: \n",
    "execute an exact-match query for the query \"magic love\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-field full-text query with field boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "EXERCISE D: \n",
    "Execute a query that searches both on tile and author\n",
    "Weights the importance of matches on the author field twice as much as matches on the title\n",
    "Sse \"shakespeare\" as query term\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining different queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "EXERCISE E:\n",
    "execute a *single* boolean query returning books that:\n",
    "- have the \"queen mary\" in the title and were written in England\n",
    "- should NOT have been published in the range of years [1850-1913]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fuzzy queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "EXERCISE F:\n",
    "execute a fuzzy query for the query \"comander\" with at most 50 expansions \n",
    "and considering transpositions\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get TF of terms in document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "EXERCISE G:\n",
    "get the term frequencies (in the title) of document with id = 4200\n",
    "consider only words with a minimum length of 4 and a minimum term frequency of 2\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION TO EXERCISE A\n",
    "\n",
    "# aggregation query\n",
    "query = {\n",
    "    \"aggregations\": {\n",
    "        \"by_category\": {\n",
    "            \"terms\": {\n",
    "                \"field\": \"country\",\n",
    "                \"size\":100\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "r = e.curl('get', f'books/_search', query)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION TO EXERCISE B\n",
    "\n",
    "# full-text query\n",
    "query = {\n",
    "    \"query\": {\n",
    "        \"match\": {\n",
    "            \"title\": {\n",
    "                \"query\": \"love magic\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "r = e.curl('get', f'books/_search', query)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION TO EXERCISE C\n",
    "\n",
    "# exact match query\n",
    "query = {\n",
    "  \"query\": {\n",
    "    \"match_phrase\": {\n",
    "      \"title\": {\n",
    "        \"query\": \"magic love\"\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "r = e.curl('get', f'books/_search', query)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION TO EXERCISE D\n",
    "\n",
    "# Full text query, multiple fields with boosting\n",
    "query = {\n",
    "\"query\": {\n",
    "    \"multi_match\": {\n",
    "            \"query\": \"shakespeare\",\n",
    "            \"fields\": [\"title\", \"author_name^2\"],\n",
    "            \"type\": \"phrase\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "r = e.curl('get', f'books/_search', query)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION TO EXERCISE E\n",
    "\n",
    "# One or more queries can be specified in each of the clauses\n",
    "# All the clauses are optional\n",
    "# MUST: A document must match all of the queries\n",
    "# MUST_NOT: A document must not match any of the queries\n",
    "# SHOULD: A document does not have to match the queries, but it is considered more relevant if it does\n",
    "# FILTER: Filters with yes/no categories\n",
    "query = {\n",
    "  \"size\" : 100,\n",
    "  \"query\": {\n",
    "    \"bool\": {\n",
    "      \"must\": [\n",
    "        {\n",
    "          \"match\": {\n",
    "                \"title\": \"queen mary\"\n",
    "          }\n",
    "        },\n",
    "        {\n",
    "          \"match\": {\n",
    "              \"country\": \"England\"\n",
    "          }\n",
    "        }\n",
    "      ],\n",
    "      \"must_not\": [\n",
    "        {\n",
    "          \"range\": {\n",
    "            \"year\": {\n",
    "                \"gte\": 1850,\n",
    "                \"lte\": 1913\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  }\n",
    "}\n",
    "r = e.curl('get', f'books/_search', query)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION TO EXERCISE F\n",
    "\n",
    "query ={\n",
    "  \"query\": {\n",
    "    \"fuzzy\": {\n",
    "      \"title\": {\n",
    "        \"value\": \"comander\",\n",
    "        \"fuzziness\": \"AUTO\",\n",
    "        \"max_expansions\": 50,\n",
    "        \"prefix_length\": 0,\n",
    "        \"transpositions\": True,\n",
    "        \"rewrite\": \"constant_score\"\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "r = e.curl('get', f'books/_search', query)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION TO EXERCISE G\n",
    "\n",
    "# https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-termvectors.html\n",
    "query = {\n",
    "    \"fields\" : [\"title\"],\n",
    "    \"term_statistics\" : True,\n",
    "    \"field_statistics\" : True,\n",
    "    \"positions\": True,\n",
    "    \"filter\": {\n",
    "        \"min_word_length\": 4,\n",
    "        \"min_term_freq\" : 2\n",
    "  }\n",
    "}\n",
    "#r = e.curl('get', f'books/_doc/{doc_ids[4200]}')\n",
    "r = e.curl('get', f'books/_termvectors/{doc_ids[4200]}', query)\n",
    "r.json()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-in-production",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "293.396px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "83929ffd1ad749d46bf46224d7a1f235b1a3279e6736dc3a23f1c3927642f57f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
